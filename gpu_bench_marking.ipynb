{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i will update this and post it on kaggle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved as .npy files\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming you have already loaded and normalized the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       ...,\n",
       "       [9],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (50000, 1))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape\n",
    "\n",
    "#50000 images, 32x32 pixels, 3 channels{rgb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([59, 62, 63], dtype=uint8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_sample(image):\n",
    "    plt.figure(figsize=(10,1))\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_sample(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'truck'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[0.23137255, 0.24313725, 0.24705882],\n",
       "          [0.16862745, 0.18039216, 0.17647059],\n",
       "          [0.19607843, 0.18823529, 0.16862745],\n",
       "          ...,\n",
       "          [0.61960784, 0.51764706, 0.42352941],\n",
       "          [0.59607843, 0.49019608, 0.4       ],\n",
       "          [0.58039216, 0.48627451, 0.40392157]],\n",
       " \n",
       "         [[0.0627451 , 0.07843137, 0.07843137],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.07058824, 0.03137255, 0.        ],\n",
       "          ...,\n",
       "          [0.48235294, 0.34509804, 0.21568627],\n",
       "          [0.46666667, 0.3254902 , 0.19607843],\n",
       "          [0.47843137, 0.34117647, 0.22352941]],\n",
       " \n",
       "         [[0.09803922, 0.09411765, 0.08235294],\n",
       "          [0.0627451 , 0.02745098, 0.        ],\n",
       "          [0.19215686, 0.10588235, 0.03137255],\n",
       "          ...,\n",
       "          [0.4627451 , 0.32941176, 0.19607843],\n",
       "          [0.47058824, 0.32941176, 0.19607843],\n",
       "          [0.42745098, 0.28627451, 0.16470588]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.81568627, 0.66666667, 0.37647059],\n",
       "          [0.78823529, 0.6       , 0.13333333],\n",
       "          [0.77647059, 0.63137255, 0.10196078],\n",
       "          ...,\n",
       "          [0.62745098, 0.52156863, 0.2745098 ],\n",
       "          [0.21960784, 0.12156863, 0.02745098],\n",
       "          [0.20784314, 0.13333333, 0.07843137]],\n",
       " \n",
       "         [[0.70588235, 0.54509804, 0.37647059],\n",
       "          [0.67843137, 0.48235294, 0.16470588],\n",
       "          [0.72941176, 0.56470588, 0.11764706],\n",
       "          ...,\n",
       "          [0.72156863, 0.58039216, 0.36862745],\n",
       "          [0.38039216, 0.24313725, 0.13333333],\n",
       "          [0.3254902 , 0.20784314, 0.13333333]],\n",
       " \n",
       "         [[0.69411765, 0.56470588, 0.45490196],\n",
       "          [0.65882353, 0.50588235, 0.36862745],\n",
       "          [0.70196078, 0.55686275, 0.34117647],\n",
       "          ...,\n",
       "          [0.84705882, 0.72156863, 0.54901961],\n",
       "          [0.59215686, 0.4627451 , 0.32941176],\n",
       "          [0.48235294, 0.36078431, 0.28235294]]],\n",
       " \n",
       " \n",
       "        [[[0.60392157, 0.69411765, 0.73333333],\n",
       "          [0.49411765, 0.5372549 , 0.53333333],\n",
       "          [0.41176471, 0.40784314, 0.37254902],\n",
       "          ...,\n",
       "          [0.35686275, 0.37254902, 0.27843137],\n",
       "          [0.34117647, 0.35294118, 0.27843137],\n",
       "          [0.30980392, 0.31764706, 0.2745098 ]],\n",
       " \n",
       "         [[0.54901961, 0.62745098, 0.6627451 ],\n",
       "          [0.56862745, 0.6       , 0.60392157],\n",
       "          [0.49019608, 0.49019608, 0.4627451 ],\n",
       "          ...,\n",
       "          [0.37647059, 0.38823529, 0.30588235],\n",
       "          [0.30196078, 0.31372549, 0.24313725],\n",
       "          [0.27843137, 0.28627451, 0.23921569]],\n",
       " \n",
       "         [[0.54901961, 0.60784314, 0.64313725],\n",
       "          [0.54509804, 0.57254902, 0.58431373],\n",
       "          [0.45098039, 0.45098039, 0.43921569],\n",
       "          ...,\n",
       "          [0.30980392, 0.32156863, 0.25098039],\n",
       "          [0.26666667, 0.2745098 , 0.21568627],\n",
       "          [0.2627451 , 0.27058824, 0.21568627]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.68627451, 0.65490196, 0.65098039],\n",
       "          [0.61176471, 0.60392157, 0.62745098],\n",
       "          [0.60392157, 0.62745098, 0.66666667],\n",
       "          ...,\n",
       "          [0.16470588, 0.13333333, 0.14117647],\n",
       "          [0.23921569, 0.20784314, 0.22352941],\n",
       "          [0.36470588, 0.3254902 , 0.35686275]],\n",
       " \n",
       "         [[0.64705882, 0.60392157, 0.50196078],\n",
       "          [0.61176471, 0.59607843, 0.50980392],\n",
       "          [0.62352941, 0.63137255, 0.55686275],\n",
       "          ...,\n",
       "          [0.40392157, 0.36470588, 0.37647059],\n",
       "          [0.48235294, 0.44705882, 0.47058824],\n",
       "          [0.51372549, 0.4745098 , 0.51372549]],\n",
       " \n",
       "         [[0.63921569, 0.58039216, 0.47058824],\n",
       "          [0.61960784, 0.58039216, 0.47843137],\n",
       "          [0.63921569, 0.61176471, 0.52156863],\n",
       "          ...,\n",
       "          [0.56078431, 0.52156863, 0.54509804],\n",
       "          [0.56078431, 0.5254902 , 0.55686275],\n",
       "          [0.56078431, 0.52156863, 0.56470588]]],\n",
       " \n",
       " \n",
       "        [[[1.        , 1.        , 1.        ],\n",
       "          [0.99215686, 0.99215686, 0.99215686],\n",
       "          [0.99215686, 0.99215686, 0.99215686],\n",
       "          ...,\n",
       "          [0.99215686, 0.99215686, 0.99215686],\n",
       "          [0.99215686, 0.99215686, 0.99215686],\n",
       "          [0.99215686, 0.99215686, 0.99215686]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [0.99607843, 0.99607843, 0.99607843],\n",
       "          [0.99607843, 0.99607843, 0.99607843],\n",
       "          ...,\n",
       "          [0.99607843, 0.99607843, 0.99607843],\n",
       "          [0.99607843, 0.99607843, 0.99607843],\n",
       "          [0.99607843, 0.99607843, 0.99607843]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.44313725, 0.47058824, 0.43921569],\n",
       "          [0.43529412, 0.4627451 , 0.43529412],\n",
       "          [0.41176471, 0.43921569, 0.41568627],\n",
       "          ...,\n",
       "          [0.28235294, 0.31764706, 0.31372549],\n",
       "          [0.28235294, 0.31372549, 0.30980392],\n",
       "          [0.28235294, 0.31372549, 0.30980392]],\n",
       " \n",
       "         [[0.43529412, 0.4627451 , 0.43137255],\n",
       "          [0.40784314, 0.43529412, 0.40784314],\n",
       "          [0.38823529, 0.41568627, 0.38431373],\n",
       "          ...,\n",
       "          [0.26666667, 0.29411765, 0.28627451],\n",
       "          [0.2745098 , 0.29803922, 0.29411765],\n",
       "          [0.30588235, 0.32941176, 0.32156863]],\n",
       " \n",
       "         [[0.41568627, 0.44313725, 0.41176471],\n",
       "          [0.38823529, 0.41568627, 0.38431373],\n",
       "          [0.37254902, 0.4       , 0.36862745],\n",
       "          ...,\n",
       "          [0.30588235, 0.33333333, 0.3254902 ],\n",
       "          [0.30980392, 0.33333333, 0.3254902 ],\n",
       "          [0.31372549, 0.3372549 , 0.32941176]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0.1372549 , 0.69803922, 0.92156863],\n",
       "          [0.15686275, 0.69019608, 0.9372549 ],\n",
       "          [0.16470588, 0.69019608, 0.94509804],\n",
       "          ...,\n",
       "          [0.38823529, 0.69411765, 0.85882353],\n",
       "          [0.30980392, 0.57647059, 0.77254902],\n",
       "          [0.34901961, 0.58039216, 0.74117647]],\n",
       " \n",
       "         [[0.22352941, 0.71372549, 0.91764706],\n",
       "          [0.17254902, 0.72156863, 0.98039216],\n",
       "          [0.19607843, 0.71764706, 0.94117647],\n",
       "          ...,\n",
       "          [0.61176471, 0.71372549, 0.78431373],\n",
       "          [0.55294118, 0.69411765, 0.80784314],\n",
       "          [0.45490196, 0.58431373, 0.68627451]],\n",
       " \n",
       "         [[0.38431373, 0.77254902, 0.92941176],\n",
       "          [0.25098039, 0.74117647, 0.98823529],\n",
       "          [0.27058824, 0.75294118, 0.96078431],\n",
       "          ...,\n",
       "          [0.7372549 , 0.76470588, 0.80784314],\n",
       "          [0.46666667, 0.52941176, 0.57647059],\n",
       "          [0.23921569, 0.30980392, 0.35294118]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.28627451, 0.30980392, 0.30196078],\n",
       "          [0.20784314, 0.24705882, 0.26666667],\n",
       "          [0.21176471, 0.26666667, 0.31372549],\n",
       "          ...,\n",
       "          [0.06666667, 0.15686275, 0.25098039],\n",
       "          [0.08235294, 0.14117647, 0.2       ],\n",
       "          [0.12941176, 0.18823529, 0.19215686]],\n",
       " \n",
       "         [[0.23921569, 0.26666667, 0.29411765],\n",
       "          [0.21568627, 0.2745098 , 0.3372549 ],\n",
       "          [0.22352941, 0.30980392, 0.40392157],\n",
       "          ...,\n",
       "          [0.09411765, 0.18823529, 0.28235294],\n",
       "          [0.06666667, 0.1372549 , 0.20784314],\n",
       "          [0.02745098, 0.09019608, 0.1254902 ]],\n",
       " \n",
       "         [[0.17254902, 0.21960784, 0.28627451],\n",
       "          [0.18039216, 0.25882353, 0.34509804],\n",
       "          [0.19215686, 0.30196078, 0.41176471],\n",
       "          ...,\n",
       "          [0.10588235, 0.20392157, 0.30196078],\n",
       "          [0.08235294, 0.16862745, 0.25882353],\n",
       "          [0.04705882, 0.12156863, 0.19607843]]],\n",
       " \n",
       " \n",
       "        [[[0.74117647, 0.82745098, 0.94117647],\n",
       "          [0.72941176, 0.81568627, 0.9254902 ],\n",
       "          [0.7254902 , 0.81176471, 0.92156863],\n",
       "          ...,\n",
       "          [0.68627451, 0.76470588, 0.87843137],\n",
       "          [0.6745098 , 0.76078431, 0.87058824],\n",
       "          [0.6627451 , 0.76078431, 0.8627451 ]],\n",
       " \n",
       "         [[0.76078431, 0.82352941, 0.9372549 ],\n",
       "          [0.74901961, 0.81176471, 0.9254902 ],\n",
       "          [0.74509804, 0.80784314, 0.92156863],\n",
       "          ...,\n",
       "          [0.67843137, 0.75294118, 0.8627451 ],\n",
       "          [0.67058824, 0.74901961, 0.85490196],\n",
       "          [0.65490196, 0.74509804, 0.84705882]],\n",
       " \n",
       "         [[0.81568627, 0.85882353, 0.95686275],\n",
       "          [0.80392157, 0.84705882, 0.94117647],\n",
       "          [0.8       , 0.84313725, 0.9372549 ],\n",
       "          ...,\n",
       "          [0.68627451, 0.74901961, 0.85098039],\n",
       "          [0.6745098 , 0.74509804, 0.84705882],\n",
       "          [0.6627451 , 0.74901961, 0.84313725]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.81176471, 0.78039216, 0.70980392],\n",
       "          [0.79607843, 0.76470588, 0.68627451],\n",
       "          [0.79607843, 0.76862745, 0.67843137],\n",
       "          ...,\n",
       "          [0.52941176, 0.51764706, 0.49803922],\n",
       "          [0.63529412, 0.61960784, 0.58823529],\n",
       "          [0.65882353, 0.63921569, 0.59215686]],\n",
       " \n",
       "         [[0.77647059, 0.74509804, 0.66666667],\n",
       "          [0.74117647, 0.70980392, 0.62352941],\n",
       "          [0.70588235, 0.6745098 , 0.57647059],\n",
       "          ...,\n",
       "          [0.69803922, 0.67058824, 0.62745098],\n",
       "          [0.68627451, 0.6627451 , 0.61176471],\n",
       "          [0.68627451, 0.6627451 , 0.60392157]],\n",
       " \n",
       "         [[0.77647059, 0.74117647, 0.67843137],\n",
       "          [0.74117647, 0.70980392, 0.63529412],\n",
       "          [0.69803922, 0.66666667, 0.58431373],\n",
       "          ...,\n",
       "          [0.76470588, 0.72156863, 0.6627451 ],\n",
       "          [0.76862745, 0.74117647, 0.67058824],\n",
       "          [0.76470588, 0.74509804, 0.67058824]]],\n",
       " \n",
       " \n",
       "        [[[0.89803922, 0.89803922, 0.9372549 ],\n",
       "          [0.9254902 , 0.92941176, 0.96862745],\n",
       "          [0.91764706, 0.9254902 , 0.96862745],\n",
       "          ...,\n",
       "          [0.85098039, 0.85882353, 0.91372549],\n",
       "          [0.86666667, 0.8745098 , 0.91764706],\n",
       "          [0.87058824, 0.8745098 , 0.91372549]],\n",
       " \n",
       "         [[0.87058824, 0.86666667, 0.89803922],\n",
       "          [0.9372549 , 0.9372549 , 0.97647059],\n",
       "          [0.91372549, 0.91764706, 0.96470588],\n",
       "          ...,\n",
       "          [0.8745098 , 0.8745098 , 0.9254902 ],\n",
       "          [0.89019608, 0.89411765, 0.93333333],\n",
       "          [0.82352941, 0.82745098, 0.8627451 ]],\n",
       " \n",
       "         [[0.83529412, 0.80784314, 0.82745098],\n",
       "          [0.91764706, 0.90980392, 0.9372549 ],\n",
       "          [0.90588235, 0.91372549, 0.95686275],\n",
       "          ...,\n",
       "          [0.8627451 , 0.8627451 , 0.90980392],\n",
       "          [0.8627451 , 0.85882353, 0.90980392],\n",
       "          [0.79215686, 0.79607843, 0.84313725]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.58823529, 0.56078431, 0.52941176],\n",
       "          [0.54901961, 0.52941176, 0.49803922],\n",
       "          [0.51764706, 0.49803922, 0.47058824],\n",
       "          ...,\n",
       "          [0.87843137, 0.87058824, 0.85490196],\n",
       "          [0.90196078, 0.89411765, 0.88235294],\n",
       "          [0.94509804, 0.94509804, 0.93333333]],\n",
       " \n",
       "         [[0.5372549 , 0.51764706, 0.49411765],\n",
       "          [0.50980392, 0.49803922, 0.47058824],\n",
       "          [0.49019608, 0.4745098 , 0.45098039],\n",
       "          ...,\n",
       "          [0.70980392, 0.70588235, 0.69803922],\n",
       "          [0.79215686, 0.78823529, 0.77647059],\n",
       "          [0.83137255, 0.82745098, 0.81176471]],\n",
       " \n",
       "         [[0.47843137, 0.46666667, 0.44705882],\n",
       "          [0.4627451 , 0.45490196, 0.43137255],\n",
       "          [0.47058824, 0.45490196, 0.43529412],\n",
       "          ...,\n",
       "          [0.70196078, 0.69411765, 0.67843137],\n",
       "          [0.64313725, 0.64313725, 0.63529412],\n",
       "          [0.63921569, 0.63921569, 0.63137255]]]]),\n",
       " array([[[[0.61960784, 0.43921569, 0.19215686],\n",
       "          [0.62352941, 0.43529412, 0.18431373],\n",
       "          [0.64705882, 0.45490196, 0.2       ],\n",
       "          ...,\n",
       "          [0.5372549 , 0.37254902, 0.14117647],\n",
       "          [0.49411765, 0.35686275, 0.14117647],\n",
       "          [0.45490196, 0.33333333, 0.12941176]],\n",
       " \n",
       "         [[0.59607843, 0.43921569, 0.2       ],\n",
       "          [0.59215686, 0.43137255, 0.15686275],\n",
       "          [0.62352941, 0.44705882, 0.17647059],\n",
       "          ...,\n",
       "          [0.53333333, 0.37254902, 0.12156863],\n",
       "          [0.49019608, 0.35686275, 0.1254902 ],\n",
       "          [0.46666667, 0.34509804, 0.13333333]],\n",
       " \n",
       "         [[0.59215686, 0.43137255, 0.18431373],\n",
       "          [0.59215686, 0.42745098, 0.12941176],\n",
       "          [0.61960784, 0.43529412, 0.14117647],\n",
       "          ...,\n",
       "          [0.54509804, 0.38431373, 0.13333333],\n",
       "          [0.50980392, 0.37254902, 0.13333333],\n",
       "          [0.47058824, 0.34901961, 0.12941176]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.26666667, 0.48627451, 0.69411765],\n",
       "          [0.16470588, 0.39215686, 0.58039216],\n",
       "          [0.12156863, 0.34509804, 0.5372549 ],\n",
       "          ...,\n",
       "          [0.14901961, 0.38039216, 0.57254902],\n",
       "          [0.05098039, 0.25098039, 0.42352941],\n",
       "          [0.15686275, 0.33333333, 0.49803922]],\n",
       " \n",
       "         [[0.23921569, 0.45490196, 0.65882353],\n",
       "          [0.19215686, 0.4       , 0.58039216],\n",
       "          [0.1372549 , 0.33333333, 0.51764706],\n",
       "          ...,\n",
       "          [0.10196078, 0.32156863, 0.50980392],\n",
       "          [0.11372549, 0.32156863, 0.49411765],\n",
       "          [0.07843137, 0.25098039, 0.41960784]],\n",
       " \n",
       "         [[0.21176471, 0.41960784, 0.62745098],\n",
       "          [0.21960784, 0.41176471, 0.58431373],\n",
       "          [0.17647059, 0.34901961, 0.51764706],\n",
       "          ...,\n",
       "          [0.09411765, 0.30196078, 0.48627451],\n",
       "          [0.13333333, 0.32941176, 0.50588235],\n",
       "          [0.08235294, 0.2627451 , 0.43137255]]],\n",
       " \n",
       " \n",
       "        [[[0.92156863, 0.92156863, 0.92156863],\n",
       "          [0.90588235, 0.90588235, 0.90588235],\n",
       "          [0.90980392, 0.90980392, 0.90980392],\n",
       "          ...,\n",
       "          [0.91372549, 0.91372549, 0.91372549],\n",
       "          [0.91372549, 0.91372549, 0.91372549],\n",
       "          [0.90980392, 0.90980392, 0.90980392]],\n",
       " \n",
       "         [[0.93333333, 0.93333333, 0.93333333],\n",
       "          [0.92156863, 0.92156863, 0.92156863],\n",
       "          [0.92156863, 0.92156863, 0.92156863],\n",
       "          ...,\n",
       "          [0.9254902 , 0.9254902 , 0.9254902 ],\n",
       "          [0.9254902 , 0.9254902 , 0.9254902 ],\n",
       "          [0.92156863, 0.92156863, 0.92156863]],\n",
       " \n",
       "         [[0.92941176, 0.92941176, 0.92941176],\n",
       "          [0.91764706, 0.91764706, 0.91764706],\n",
       "          [0.91764706, 0.91764706, 0.91764706],\n",
       "          ...,\n",
       "          [0.92156863, 0.92156863, 0.92156863],\n",
       "          [0.92156863, 0.92156863, 0.92156863],\n",
       "          [0.91764706, 0.91764706, 0.91764706]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.34117647, 0.38823529, 0.34901961],\n",
       "          [0.16862745, 0.2       , 0.14509804],\n",
       "          [0.0745098 , 0.09019608, 0.04313725],\n",
       "          ...,\n",
       "          [0.6627451 , 0.72156863, 0.70196078],\n",
       "          [0.71372549, 0.77254902, 0.75686275],\n",
       "          [0.7372549 , 0.79215686, 0.78823529]],\n",
       " \n",
       "         [[0.32156863, 0.37647059, 0.32156863],\n",
       "          [0.18039216, 0.22352941, 0.14117647],\n",
       "          [0.14117647, 0.17254902, 0.08627451],\n",
       "          ...,\n",
       "          [0.68235294, 0.74117647, 0.71764706],\n",
       "          [0.7254902 , 0.78431373, 0.76862745],\n",
       "          [0.73333333, 0.79215686, 0.78431373]],\n",
       " \n",
       "         [[0.33333333, 0.39607843, 0.3254902 ],\n",
       "          [0.24313725, 0.29411765, 0.18823529],\n",
       "          [0.22745098, 0.2627451 , 0.14901961],\n",
       "          ...,\n",
       "          [0.65882353, 0.71764706, 0.69803922],\n",
       "          [0.70588235, 0.76470588, 0.74901961],\n",
       "          [0.72941176, 0.78431373, 0.78039216]]],\n",
       " \n",
       " \n",
       "        [[[0.61960784, 0.74509804, 0.87058824],\n",
       "          [0.61960784, 0.73333333, 0.85490196],\n",
       "          [0.54509804, 0.65098039, 0.76078431],\n",
       "          ...,\n",
       "          [0.89411765, 0.90588235, 0.91764706],\n",
       "          [0.92941176, 0.9372549 , 0.95294118],\n",
       "          [0.93333333, 0.94509804, 0.96470588]],\n",
       " \n",
       "         [[0.66666667, 0.78431373, 0.89803922],\n",
       "          [0.6745098 , 0.78039216, 0.88627451],\n",
       "          [0.59215686, 0.69019608, 0.78823529],\n",
       "          ...,\n",
       "          [0.90980392, 0.90980392, 0.9254902 ],\n",
       "          [0.96470588, 0.96470588, 0.98039216],\n",
       "          [0.96470588, 0.96862745, 0.98431373]],\n",
       " \n",
       "         [[0.68235294, 0.78823529, 0.88235294],\n",
       "          [0.69019608, 0.78431373, 0.87058824],\n",
       "          [0.61568627, 0.70196078, 0.78039216],\n",
       "          ...,\n",
       "          [0.90196078, 0.89803922, 0.90980392],\n",
       "          [0.98039216, 0.97647059, 0.98431373],\n",
       "          [0.96078431, 0.95686275, 0.96862745]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.12156863, 0.15686275, 0.17647059],\n",
       "          [0.11764706, 0.15294118, 0.17254902],\n",
       "          [0.10196078, 0.1372549 , 0.15686275],\n",
       "          ...,\n",
       "          [0.14509804, 0.15686275, 0.18039216],\n",
       "          [0.03529412, 0.05098039, 0.05490196],\n",
       "          [0.01568627, 0.02745098, 0.01960784]],\n",
       " \n",
       "         [[0.09019608, 0.13333333, 0.15294118],\n",
       "          [0.10588235, 0.14901961, 0.16862745],\n",
       "          [0.09803922, 0.14117647, 0.16078431],\n",
       "          ...,\n",
       "          [0.0745098 , 0.07843137, 0.09411765],\n",
       "          [0.01568627, 0.02352941, 0.01176471],\n",
       "          [0.01960784, 0.02745098, 0.01176471]],\n",
       " \n",
       "         [[0.10980392, 0.16078431, 0.18431373],\n",
       "          [0.11764706, 0.16862745, 0.19607843],\n",
       "          [0.1254902 , 0.17647059, 0.20392157],\n",
       "          ...,\n",
       "          [0.01960784, 0.02352941, 0.03137255],\n",
       "          [0.01568627, 0.01960784, 0.01176471],\n",
       "          [0.02745098, 0.03137255, 0.02745098]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0.07843137, 0.05882353, 0.04705882],\n",
       "          [0.0745098 , 0.05490196, 0.04313725],\n",
       "          [0.05882353, 0.05490196, 0.04313725],\n",
       "          ...,\n",
       "          [0.03921569, 0.03529412, 0.02745098],\n",
       "          [0.04705882, 0.04313725, 0.03529412],\n",
       "          [0.05098039, 0.04705882, 0.03921569]],\n",
       " \n",
       "         [[0.08235294, 0.0627451 , 0.05098039],\n",
       "          [0.07843137, 0.0627451 , 0.05098039],\n",
       "          [0.07058824, 0.06666667, 0.04705882],\n",
       "          ...,\n",
       "          [0.03921569, 0.03529412, 0.02745098],\n",
       "          [0.03921569, 0.03529412, 0.02745098],\n",
       "          [0.04705882, 0.04313725, 0.03529412]],\n",
       " \n",
       "         [[0.08235294, 0.0627451 , 0.05098039],\n",
       "          [0.08235294, 0.06666667, 0.04705882],\n",
       "          [0.07843137, 0.07058824, 0.04313725],\n",
       "          ...,\n",
       "          [0.04705882, 0.04313725, 0.03529412],\n",
       "          [0.04705882, 0.04313725, 0.03529412],\n",
       "          [0.05098039, 0.04705882, 0.03921569]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.12941176, 0.09803922, 0.05098039],\n",
       "          [0.13333333, 0.10196078, 0.05882353],\n",
       "          [0.13333333, 0.10196078, 0.05882353],\n",
       "          ...,\n",
       "          [0.10980392, 0.09803922, 0.20392157],\n",
       "          [0.11372549, 0.09803922, 0.22745098],\n",
       "          [0.09019608, 0.07843137, 0.16470588]],\n",
       " \n",
       "         [[0.12941176, 0.09803922, 0.05490196],\n",
       "          [0.13333333, 0.10196078, 0.05882353],\n",
       "          [0.13333333, 0.10196078, 0.05882353],\n",
       "          ...,\n",
       "          [0.10588235, 0.09411765, 0.20392157],\n",
       "          [0.10588235, 0.09411765, 0.21960784],\n",
       "          [0.09803922, 0.08627451, 0.18431373]],\n",
       " \n",
       "         [[0.12156863, 0.09019608, 0.04705882],\n",
       "          [0.1254902 , 0.09411765, 0.05098039],\n",
       "          [0.12941176, 0.09803922, 0.05490196],\n",
       "          ...,\n",
       "          [0.09411765, 0.09019608, 0.19607843],\n",
       "          [0.10196078, 0.09019608, 0.20784314],\n",
       "          [0.09803922, 0.07843137, 0.18431373]]],\n",
       " \n",
       " \n",
       "        [[[0.09803922, 0.15686275, 0.04705882],\n",
       "          [0.05882353, 0.14117647, 0.01176471],\n",
       "          [0.09019608, 0.16078431, 0.07058824],\n",
       "          ...,\n",
       "          [0.23921569, 0.32156863, 0.30588235],\n",
       "          [0.36078431, 0.44313725, 0.43921569],\n",
       "          [0.29411765, 0.34901961, 0.36078431]],\n",
       " \n",
       "         [[0.04705882, 0.09803922, 0.02352941],\n",
       "          [0.07843137, 0.14509804, 0.02745098],\n",
       "          [0.09411765, 0.14117647, 0.05882353],\n",
       "          ...,\n",
       "          [0.45098039, 0.5254902 , 0.54117647],\n",
       "          [0.58431373, 0.65882353, 0.69411765],\n",
       "          [0.40784314, 0.45882353, 0.51372549]],\n",
       " \n",
       "         [[0.04705882, 0.09803922, 0.04313725],\n",
       "          [0.05882353, 0.11372549, 0.02352941],\n",
       "          [0.13333333, 0.15686275, 0.09411765],\n",
       "          ...,\n",
       "          [0.60392157, 0.6745098 , 0.71372549],\n",
       "          [0.61568627, 0.68627451, 0.75294118],\n",
       "          [0.45490196, 0.50588235, 0.59215686]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.39215686, 0.50588235, 0.31764706],\n",
       "          [0.40392157, 0.51764706, 0.32941176],\n",
       "          [0.40784314, 0.5254902 , 0.3372549 ],\n",
       "          ...,\n",
       "          [0.38039216, 0.50196078, 0.32941176],\n",
       "          [0.38431373, 0.49411765, 0.32941176],\n",
       "          [0.35686275, 0.4745098 , 0.30980392]],\n",
       " \n",
       "         [[0.40392157, 0.51764706, 0.3254902 ],\n",
       "          [0.40784314, 0.51372549, 0.3254902 ],\n",
       "          [0.41960784, 0.52941176, 0.34117647],\n",
       "          ...,\n",
       "          [0.39607843, 0.51764706, 0.34117647],\n",
       "          [0.38823529, 0.49803922, 0.32941176],\n",
       "          [0.36078431, 0.4745098 , 0.30980392]],\n",
       " \n",
       "         [[0.37254902, 0.49411765, 0.30588235],\n",
       "          [0.37254902, 0.48235294, 0.29803922],\n",
       "          [0.39607843, 0.50196078, 0.31764706],\n",
       "          ...,\n",
       "          [0.36470588, 0.48627451, 0.31372549],\n",
       "          [0.37254902, 0.48235294, 0.31764706],\n",
       "          [0.36078431, 0.47058824, 0.31372549]]],\n",
       " \n",
       " \n",
       "        [[[0.28627451, 0.30588235, 0.29411765],\n",
       "          [0.38431373, 0.40392157, 0.44313725],\n",
       "          [0.38823529, 0.41568627, 0.44705882],\n",
       "          ...,\n",
       "          [0.52941176, 0.58823529, 0.59607843],\n",
       "          [0.52941176, 0.58431373, 0.60392157],\n",
       "          [0.79607843, 0.84313725, 0.8745098 ]],\n",
       " \n",
       "         [[0.27058824, 0.28627451, 0.2745098 ],\n",
       "          [0.32941176, 0.34901961, 0.38039216],\n",
       "          [0.26666667, 0.29411765, 0.31764706],\n",
       "          ...,\n",
       "          [0.33333333, 0.37254902, 0.34901961],\n",
       "          [0.27843137, 0.32156863, 0.31372549],\n",
       "          [0.47058824, 0.52156863, 0.52941176]],\n",
       " \n",
       "         [[0.27058824, 0.28627451, 0.2745098 ],\n",
       "          [0.35294118, 0.37254902, 0.39215686],\n",
       "          [0.24313725, 0.27843137, 0.29019608],\n",
       "          ...,\n",
       "          [0.29019608, 0.31764706, 0.2745098 ],\n",
       "          [0.20784314, 0.24313725, 0.21176471],\n",
       "          [0.24313725, 0.29019608, 0.27058824]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.48235294, 0.50196078, 0.37647059],\n",
       "          [0.51764706, 0.51764706, 0.4       ],\n",
       "          [0.50588235, 0.50196078, 0.39215686],\n",
       "          ...,\n",
       "          [0.42352941, 0.41960784, 0.34509804],\n",
       "          [0.24313725, 0.23529412, 0.21568627],\n",
       "          [0.10588235, 0.10588235, 0.10980392]],\n",
       " \n",
       "         [[0.45098039, 0.4745098 , 0.35686275],\n",
       "          [0.48235294, 0.48627451, 0.37254902],\n",
       "          [0.50588235, 0.49411765, 0.38823529],\n",
       "          ...,\n",
       "          [0.45098039, 0.45490196, 0.36862745],\n",
       "          [0.25882353, 0.25490196, 0.23137255],\n",
       "          [0.10588235, 0.10588235, 0.10588235]],\n",
       " \n",
       "         [[0.45490196, 0.47058824, 0.35294118],\n",
       "          [0.4745098 , 0.47843137, 0.36862745],\n",
       "          [0.50588235, 0.50196078, 0.39607843],\n",
       "          ...,\n",
       "          [0.45490196, 0.45098039, 0.36862745],\n",
       "          [0.26666667, 0.25490196, 0.22745098],\n",
       "          [0.10588235, 0.10196078, 0.10196078]]]]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled,x_test_scaled = x_train/255.0,x_test/255.0\n",
    "\n",
    "x_train_scaled,x_test_scaled    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(y):\n",
    "    return tf.keras.utils.to_categorical(y,num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_categorical = to_one_hot(y_train)\n",
    "y_test_categorical = to_one_hot(y_test)\n",
    "\n",
    "y_train_categorical[0],y_test_categorical[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neural network 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neural network 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - accuracy: 0.1874 - loss: 2.2256\n",
      "Epoch 2/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - accuracy: 0.3081 - loss: 1.9278\n",
      "Epoch 3/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.3400 - loss: 1.8671\n",
      "Epoch 4/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.3513 - loss: 1.8376\n",
      "Epoch 5/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.3621 - loss: 1.8202\n",
      "Epoch 6/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 25ms/step - accuracy: 0.3667 - loss: 1.8080\n",
      "Epoch 7/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.3680 - loss: 1.7991\n",
      "Epoch 8/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - accuracy: 0.3654 - loss: 1.8165\n",
      "Epoch 9/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 24ms/step - accuracy: 0.3337 - loss: 1.9184\n",
      "Epoch 10/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - accuracy: 0.2474 - loss: 3.2721\n",
      "Epoch 11/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - accuracy: 0.1995 - loss: 9.9142\n",
      "Epoch 12/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.1871 - loss: 21.8678\n",
      "Epoch 13/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 24ms/step - accuracy: 0.1778 - loss: 40.5384\n",
      "Epoch 14/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - accuracy: 0.1808 - loss: 64.9102\n",
      "Epoch 15/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.1848 - loss: 109.1321\n",
      "Epoch 16/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.1809 - loss: 215.8253\n",
      "Epoch 17/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - accuracy: 0.1883 - loss: 299.5734\n",
      "Epoch 18/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - accuracy: 0.1872 - loss: 421.3480\n",
      "Epoch 19/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - accuracy: 0.1878 - loss: 372.3346\n",
      "Epoch 20/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.1895 - loss: 310.4675\n",
      "Epoch 21/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.1429 - loss: nan\n",
      "Epoch 22/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 24ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 23/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 24/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 25/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 26/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 27/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 28/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 29/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 30/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 31/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 32/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 33/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 34/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 35/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 36/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 37/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 38/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 39/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 40/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 41/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 42/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 43/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 44/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 45/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 46/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 47/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 48/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 49/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 50/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 51/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 52/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 53/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 54/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 55/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 56/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 57/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: nan\n",
      "Epoch 58/100\n",
      "\u001b[1m 727/1563\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m model2\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_categorical\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Downloads/deep learning notebooks/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Downloads/deep learning notebooks/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Downloads/deep learning notebooks/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m     ):\n\u001b[0;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Downloads/deep learning notebooks/.venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Downloads/deep learning notebooks/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Downloads/deep learning notebooks/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Downloads/deep learning notebooks/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Downloads/deep learning notebooks/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Downloads/deep learning notebooks/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Downloads/deep learning notebooks/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Downloads/deep learning notebooks/.venv/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Downloads/deep learning notebooks/.venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Create the model\n",
    "model2 = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(32, 32, 3)),\n",
    "    keras.layers.Dense(3000, activation='relu'),\n",
    "    keras.layers.Dense(1000, activation='relu'),\n",
    "    keras.layers.Dense(500, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')  # Use softmax for multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the model with SGD optimizer\n",
    "optimizer = SGD(learning_rate=0.0001)  # You can adjust the learning rate\n",
    "model2.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model2.fit(x_train_scaled, y_train_categorical, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.1922 - loss: 73.1292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[73.77992248535156, 0.18889999389648438]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(x_test_scaled,y_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([5. 7. 9.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
